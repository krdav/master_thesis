\chapter{Ancestral sequence reconstruction of the B cell receptor phylogeny}

\section{Introduction}
With the wide availability and cost reductions of high-throughput sequencing (HTS), it is getting commonly applied for studying the immune response through sequencing of the BCR and TCR repertoire.
Phylogenetic reconstruction of the evolution of the BCRs has recently gotten increasing attention because of its possible use in studying vaccine responses.
There is a hope that with better understanding of the evolutionary trajectories BCRs undergo, that the fate of the immune response can be modelled in a probabilistic framework, and that this will lead to new avenues in vaccine design and, possibly, finally enabling vaccination against HIV and achieving broad influenza immunity.

By and large, the use of phylogenetics in BCR GC evolution has been made with the standard assumptions of site independence, constant mutation rates etc. using methods like maximum parsimony (MP) \cite{tas2016visualizing}, \cite{Barak2008-fw} and maximum likelihood (ML) \cite{Doria-Rose2014-vi}, \cite{Hoehn2016-wg}.
But it is important to note that most algorithms for phylogenetic inference have been made to study population genetics, largely evolving under a neutrality, or to track the evolution of organisms over millions of years.
The consequences being that model assumptions have been formulated and validated in a completely different context than the highly selective, small population evolution that BCRs undergo in the germinal center (GC) reaction.
In contrast, BCR evolution has some interesting features that violates the assumption of classical phylogenetic methods e.g.\ the mutation model is DNA context sensitive, the root of the tree is a known and fixed state, high selection pressure on selected sites, sampled ancestors, very high mutation rates etc.
We are not aware of any study that does a broad comparison of these commonly used phylogenetic inference tools in a parameter regime relevant to BCR sequence evolution.

Validation studies are needed in order to understand weaknesses in the existing phylogenetic tool-chain, and opportunities to develop tools specific to the BCR case.
Sequence simulation is the cornerstone of all validation studies, but unfortunately there has been no publicly available method for simulation of BCR sequence evolution.
Multiple articles have described simulations of VDJ recombined sequences \cite{safonova2015igsimulator}, \cite{ralph2016likelihood}, \cite{russ2015htjoinsolver} and few have also described simulation of B cell maturation \cite{shlomchik1998clone}, \cite{kleinstein2003estimating}.
Recombination centric simulations are usually not using a realistic model for simulating the SHM induced mutations in the GC reaction because their purpose is to test VDJ inference, and the few simulation programs emulating maturation are either closed source, does not model central parts of the GC reaction or entirely avoids dealing with sequences.
We are using a branching process, with and without selection, developed specifically for modelling the outcome of SHM in the GC reaction, in order to test BCR lineage tree reconstruction under complex evolution.

In this work we benchmark the performance of classical phylogenetic tools when applied to B cell receptor sequences, including tools for phylogenetic tree inference and for ancestral sequence reconstruction (ASR).
We do so with a realistic sequence simulation framework that can be used in the future for validating BCR specific methods as they develop.




\subsection{Ancestral sequence reconstruction}
When a phylogeny is inferred using a tree as a model for evolution, the tree will contain internal nodes connecting the observations.
An internal state is the inferred common ancestor of a number of leaves and/or branches, sometimes referred to as an ancestral state.
Internal nodes are typically unknown, unobserved states, either explicitly defined by a sequence as in a parsimony tree, or defined by a likelihood function as in model based phylogenies.
When a likelihood function is used there is no longer a well defined ancestral sequence, instead this needs to be found as the maximum likelihood estimate (MLE) sequence.
The MLE can be defined in either of two ways; marginal or joint reconstruction.

In a marginal reconstruction the MLE sequence for one node is independent of the MLE of another i.e.\ $a_1 = \operatorname{max}(l(a_1 | t)), a_2 = \operatorname{max}(l(a_2 | t)), \hdots, a_n = \operatorname{max}(l(a_n | t))$, where $l$ is the likelihood function given a tree with branch length and data, $t$, and $a_i$ is an ancestral sequence on internal node $i$.
This makes it easy to find ancestral sequences by iterating through all internal nodes in arbitrary order.

However, once an ancestral sequence has been found and is fixed to its internal node this changes the likelihood function for the rest of the tree.
In fact all internal states are interdependent, and while this is ignored in the marginal reconstruction it is taken into account in joint reconstruction by maximizing the likelihood of all ancestral states at once i.e.\ $a_1, a_2, \hdots, a_n = \operatorname{max}(l(a_1, a_2, \hdots, a_n | t))$.
This is a non trivial task to minimize, and though Pupko et al.\ \cite{pupko2000fast} showed how to speed up the joint reconstruction algorithm, most software uses the more simple marginal reconstruction.

While joint reconstruction is the probabilistically correct way of inferring ancestral sequences, there is less clarity about whether or not this changes the estimated sequences.
The model based methods tested in this work are all using marginal reconstruction to find ancestral sequences, and therefore this will also be used in our validation.






\section{Methods}

\subsection{Measuring correctness of ancestral reconstruction}
In the following section we will introduce a benchmark metric for ancestral sequence reconstruction, we call this metric correctness of ancestral reconstruction (COAR).
The correctness of a reconstruction compared to the true evolutionary history can be measured by multiple similarity measures e.g.\ a) topological similarity, b) branch length similarity and c) sequence similarity between inferred and real ancestors.
All these measures are inter-dependent e.g.\ the inferred sequences are affected by the branch lengths and the topology and the branch lengths are determined given a topology etc.

Assume the loss function for ancestral sequence reconstruction is comprised of the three above mentioned terms.
The tree topology is the model framework of the phylogeny by which we can extract useful information like relatedness, ancestral sequences, distances and more.
In a model based phylogeny branch lengths are a measure for the expected number of substitutions per-site, so picking the correct branch lengths are important for reconstruction.
If the model underlying the phylogeny is a clock-model, where the branch lengths are related to evolutionary time, then the branch lengths are also interpretable.
Otherwise interpretation is more difficult, and regardless of their magnitude, the branch lengths are merely numbers adjusted by the underlying phylogenetic model, and therefore the correctness of these are of secondary importance.
%Lastly, the actual inferred ancestral sequences are determined by a combination of the underlying substitution model, the chosen tree and its branch lengths.
While inferring correct tree topology is important in its own right, the correctness of the inferred ancestral sequences are the foremost important objective of most BCR phylogenies where these sequences are used for applications involving DNA synthesis, protein expression and lab tests.
For this reason, the sole purpose of the COAR metric is to capture the correctness of the inferred ancestral sequences.
In particular, we would like to have a loss function that does not break when minor parts of the tree topology is incorrect while ASR is perfect.

The purpose of COAR is to compare two trees build the same leaves; let's call them the true and inferred tree.
When performing ASR the desired result is often to reconstruct the internal nodes in the direct path going from a leaf to the root, as illustrated in figure \ref{fig:ASR_true_vs_inferred}.
This path is extracted by starting at a leaf node and traversing upwards in the tree, parent by parent, until the root is reached.
In the following, this list of sequences will be referred to as the ancestral lineage.
The correct ancestral lineage is the objective so let's use this to define COAR, and let's also set COAR to be the expected per-site error in such a reconstruction.
Now following the example in figure \ref{fig:ASR_true_vs_inferred}, often there will be small differences in tree topology between the true and inferred tree, and these will likely make the number of internal states in the ancestral lineages differ.
This makes comparison difficult because two lists of different length cannot be element-wise compared.
The lists could be made equal length by adding gaps, but then a systematic way of adding these would be necessary.

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/ASR_true_vs_inferred.pdf}
    \caption{
        \label{fig:ASR_true_vs_inferred}
        True vs.\ inferred tree with colored leaves and grey ancestral states. Reconstruction from the light blue leaf is marked by a dashed red line and annotated with genotypes in parenthesis.
        N is the naive sequence, L is the leaf sequence and the $A$s are ancestors $1, 2, \hdots, n$ with either true or inferred marked by $t$ or $i$, respectively and appended to the subscript.
        The inferred tree has misplaced the branch leading to the light blue node, resulting in a missing ancestor sequence.
        The missing ancestor is treated as a missing realization in the inferred mutation process.
    }
\end{figure}

\clearpage
The basis of COAR is a list comparison progressing element-wise through the list i.e.\ element 1 in list 1 compared to element 1 in list 2, next, element 2 in list 1 compared to element 2 in list 2 etc.
For lists of similar length the list comparison is easy, it will simply be the cumulated distance from list element comparisons, corresponding to the sum of Hamming distances between inferred and true ancestors in the lists.
When lists are not equally long, one or more gaps must be introduced into one of the lists; we choose to do so in such a way that the list similarity is maximized.
This is an alignment problem with matches/mismatches/gap points and penalties solved by score maximization using the Needleman-Wunsch algorithm \cite{needleman1970general}.
We define the global alignment so that it has to start at the root and end at the leaf because these two states are known for both the true and inferred phylogenies.
We further restrict the Needleman-Wunsch algorithm so that gaps are only allowed to be introduced into the shortest of the two lists being aligned, this forces the maximum number of node comparisons.
With this restriction on gaps, the number of gaps is determined solely by the differences in list lengths and, as long as the gap penalty is less than or equal to zero, the gaps will always be at the same positions.
Practically, this means that the magnitude of the gap penalty only serves the purpose of introducing an extra penalty for inferring a wrong topology and can be adjusted to put more or less emphasis on tree topological correctness.
%A larger gap penalty puts more emphasis on correctness of tree topology.

One interpretation of the COAR value is that it is the distance between the true and inferred mutation histories, as illustrated in in figure \ref{fig:mutation_process}.
In this representation of an ancestral lineage the root and the leaf are two fixed states with a continuous mutation process running between them.
The internal nodes in the ancestral lineage are discrete states in the continuous process, on the true tree these corresponds to actual cells but on the inferred tree they need not correspond to actual observed genotypes.
Instead we can think about them as realizations along the continuous mutation process defined by the inferred tree.
The COAR value is then a similarity measured between the true cell genotype and the inferred realizations, each sampled from the true and inferred mutation processes respectively, and in the case of a mismatch between the number of realizations and cells, a gap will be introduced in the alignment to compensate.
%In this view more sequences in the inferred ancestral lineage means more realizations along the mutational path and vice versa.
Those extra inferred realizations could in fact be correct sequences with no cell observations on the true phylogeny.
For this reason we set the gap penalty to be zero, so that the COAR value will only reflect the difference between comparable states and be indifferent to the possible differences in tree topology.
The correctness of the tree topology can the be assessed separately by other metrics such as Robinson-Foulds distance \cite{robinson1981comparison}.

\clearpage
\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.5\textwidth]{figures/mutation_process2.pdf}
    \caption{
        \label{fig:mutation_process}
        One interpretation of the COAR value is that it is the distance between the true and inferred mutation histories, here shown by the true and inferred ancestral lineage nodes of an example phylogeny.
        The true ancestral lineage (left side) represents actual observed cells where the genotype is a known constant.
        The inferred ancestral lineage (right side) represents the estimated genotypes at branching points along the inferred topology.
        In some cases there is a mis-correspondence between observed cells in the true phylogeny and the branching points in the inferred tree.
        These are treated as missing realizations and ignored in the alignment of the two mutation histories.
    }
\end{figure}





%%% For phylogenies with known roots
%The ordered list of sequences constitute the reconstructed ancestral lineage for the leaves picked and it always start with the root sequence and ends with the leaf.
% The both the true and inferred tree may have any number of sequences in this list however there must be as minimum 2; the root and the leaf.


Using the aligned ancestral lineages it is now possible to derive a score, similar to a sequence alignment score.
We use negative penalties and zero points for matches, and furthermore normalize the alignment score to the smallest possible score for that lineage, yielding our measure for correctness of ancestral reconstruction:
$$
\COAR_i = \frac{\alignscore(\leaf_i)}{\alignscore_{\min}(\leaf_i)}
$$
Where alignscore is the score of the alignment between the true and inferred ancestral lineages and in the denominator, $\alignscore_{min}$ is the smallest possible score given the number and length of the sequences in the ancestral lineages.
The alignment score is defined in terms of penalties, so all values are negative, $\alignscore \leq 0$.
Likewise the smallest possible alignment score is negative thereby canceling out the negatives to make COAR positive.

COAR is defined in the range from 0 to 1, where 0 is a perfect ancestral sequence reconstruction and 1 is the worst.
The COAR value is comparable across different trees, methods and datasets because of this normalization.
Its value can be interpreted as the average per-site error in the inferred ancestral lineage sequences.
COAR for a single ancestral lineage can be expanded to the tree level by calculating the mean COAR value for the whole tree:
$$
\operatorname{mean}(\COAR) = \left. \sum^{L_N}_{i=1} \frac{\alignscore(\leaf_i)}{\alignscore_{\min}(\leaf_i)} \right/ L_N
$$
Where $L_N$ is the number of leaves on the tree.




\subsubsection{Calculating COAR values - example with a known root}
As an example of how the COAR metric works we will present a small example, summarized in figure \ref{fig:ASR_true_vs_inferred} with the light blue leaf chosen for lineage reconstruction and the true and inferred ancestral lineages marked in each tree with red dashed lines.
The example is on the phylogeny of a B cell receptor (BCR) clonal family in which case the root sequence is a known state called the naive sequence.
Assume that the true phylogeny is known with corresponding ancestral sequences along the tree.
Given only the sequences, a phylogeny can be inferred using any method e.g.\ maximum parsimony, maximum likelihood, Bayesian methods etc.
We make the restriction that only one inferred tree is evaluated i.e.\ if multiple equally parsimonious trees exist one should be chosen at random, or if a Bayesian method is used the maximum a posterior tree should be chosen.
% We make the restriction that only one inferred tree is evaluated i.e.\ if multiple equally parsimonious trees exist one should be chosen at random, or if a Bayesian method is used the maximum posterior tree or a random tree weighted according to the posterior distribution should be chosen.
% The true tree will often be derived from simulations while the inferred tree can be made by many different tree algorithms nevertheless these are the basic input to determine the COAR.

Now take a leaf sequence on the tree and reconstruct its ancestral lineage by extracting the parent, the parent's parent, etc.\ until the root is reached.
Results for the trees in figure \ref{fig:ASR_true_vs_inferred} are tabulated in table \ref{true_vs_inferred_table}.
This ordered list of sequences constitute the reconstructed ancestral lineage for the chosen leaf and it always start at the root and ends with the leaf sequence.
Both the true and inferred tree may have any number of sequences in this list, however there must be as minimum 2, the root and the leaf.
In this example the root state is given a priori as the naive BCR sequence, so we are imposing the restriction on the alignment that it must start with the root and end at the leaf, and since these are known states they do not count towards the COAR value.

\begin{table}[ht!]
\centering
\begin{tabular}{rcc}
\multicolumn{1}{c}{} & True   & Inferred \\ \hline
Naive (N)            & \texttt{AAA} & \texttt{AAA}         \\ \hline
$A_1$                & \texttt{AAT} & \texttt{TAT}         \\ \hline
$A_2$                & \texttt{ATT} & -                    \\ \hline
Leaf (L)             & \texttt{TTT} & \texttt{TTT}         \\ \hline
\end{tabular}
    \caption{
         \label{true_vs_inferred_table}
             Reconstructed ancestral lineage for true and inferred trees as shown in figure \ref{fig:ASR_true_vs_inferred}.
             }
\end{table}

%%%% Maybe include abundances in the example later:
\iffalse

\begin{table}[ht!]
\centering
\label{table:true_vs_inferred_table}
\begin{tabular}{rccc}
\multicolumn{1}{c}{} & True   & Inferred & Abundance \\ \hline
Naive (N)            & \texttt{AAA} & \texttt{AAA}   & 1         \\ \hline
$A_1$                & \texttt{AAT} & \texttt{AAT}   & 2         \\ \hline
$A_2$                & \texttt{ATT} &                  & 20        \\ \hline
Leaf (L)             & \texttt{TTT} & \texttt{TTT}   & 5         \\ \hline
\end{tabular}
\end{table}

\fi

%To align the true vs.\ inferred lists of reconstructed ancestral lineages we will consider each sequence as a state that can be compared to another state to find

In the case of a wrongly inferred topology the true and inferred list of ancestral lineage sequences can have different length, so we need a way of finding the best possible alignment between these lists.
We know the start and end of this alignment but the sequences in between are free to be shifted up or down to maximize the alignment fit.
We adapt the Needleman and Wunsch dynamic program solution \cite{needleman1970general} to solve the alignment problem in squared time complexity.
A notable difference to the original algorithm is that it was intended to align two sequences of characters, like DNA or amino acids, while in this application a list of whole sequences are aligned.
%Here we work through an example in detail.

% The first step in the alignment algorithm is to calculate a distance matrix of all pairwise distances.
The first step in the alignment algorithm is to calculate a score matrix of all pairwise sequence comparisons.
For this example we use the negative Hamming distance as a score, however, the score function can be extended to reflect different situations, like larger penalty for non-synonymous rather than synonymous mutations.
By using simple Hamming distances, we will in this example be weighting all mismatches equally.
The score matrix is tabulated in table \ref{distance_matrix}.
% We use negative scores to reflect that mismatches represents a loss.
% This matrix is called the score matrix to stress the fact that it is not exclusively for string distances but can accommodate more advanced loss functions.

\begin{table}[ht!]
\centering
\begin{tabular}{c|r|r|r|r}
\rowcolor[HTML]{EFEFEF}
                                 & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}N} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}$A_{1t}$} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}$A_{2t}$} & \multicolumn{1}{c}{\cellcolor[HTML]{EFEFEF}L} \\ \hline
\cellcolor[HTML]{EFEFEF}N        & 0                                              & -1                                                    & -2                                                    & \multicolumn{1}{r|}{-3}                       \\ \hline
\cellcolor[HTML]{EFEFEF}$A_{1i}$ & -2                                             & -1                                                     & -2                                                    & \multicolumn{1}{r|}{-1}                       \\ \hline
\cellcolor[HTML]{EFEFEF}L        & -3                                             & -2                                                    & -1                                                    & \multicolumn{1}{r|}{0}                        \\ \hline
\end{tabular}
    \caption{
         \label{distance_matrix}
             Score matrix based on all pairwise distances between the sequence in figure \ref{fig:ASR_true_vs_inferred}.
             }
\end{table}

% To allow for different lengths of true and inferred list of ancestral sequences they are align with the possibility of a gap to be introduced.
% This gap should be penalized to reflect the difference between true and inferred ancestral lineages.
%%% Next line is true only because the gap penalty is influencing the maximum penalty and thereby shifting the COAR. It will never influence the actual alignment.
%%%%%%% This depends or whether a restriction is put on the gap introduction. E.g.\ this could be allowed:
% AA-AAA
% BBB-BB
% The magnitude of the gap penalty is determined to put appropriate amount of emphasis on correctness of the tree topology.
% In this example we will use a hard penalty on wrong topology by setting the gap penalty to -10.
% In a realistic setting the gap penalty should depend on the length of the sequences on the input tree and e.g.\ a gap penalty of 10\% of the sequence length would be sufficient to penalize wrong topologies without over emphasizing the importance compared to similarity in ancestral sequences.
% So in the example of an input tree with sequences of length 300 a gap penalty of -30 would be a good choice.
%It it worth to notice that in this example, because the first and last sequence in the alignment is fixed to the root and leaf, the number of gaps is fixed

Now we are ready to initializing the alignment grid used in the dynamic programming solution.
Initialization is started by inserting the scores of pure gap characters i.e.\ first row and first column (table \ref{NW_fill_table1}), and we enforce alignment of the two root sequences by setting these gap penalties to negative infinity.
Similarly, we disallow introduction of gaps in the longest of the two lists by penalizing these as negative infinity (table \ref{NW_full_table}).
Setting certain gap penalties to negative infinity is a simple way of dealing with disallowed gaps and it also works well for implementation.
\begin{table}[ht!]
\centering
\begin{tabular}{c|r|r|r|r|r|}
\rowcolor[HTML]{EFEFEF}
                                 & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}-} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}N} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}$A_{1t}$} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}$A_{2t}$} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}L} \\ \hline
\cellcolor[HTML]{EFEFEF}-        & 0                                              & -Inf                                            & -Inf                                                   & -Inf                                                   & -Inf                                            \\ \hline
\cellcolor[HTML]{EFEFEF}N        & -Inf                                            & $\rightarrowtriangle$                                            &                                                    &                                                    &                                             \\ \hline
\cellcolor[HTML]{EFEFEF}$A_{1i}$ & -Inf                                            &                                             &                                                    &                                                    &                                             \\ \hline
\cellcolor[HTML]{EFEFEF}L        & -Inf                                            &                                             &                                                    &                                                    &                                             \\ \hline
\end{tabular}
    \caption{
         \label{NW_fill_table1}
             The starting alignment grid, initialized with negative infinite gap penalties to disallow gap opening in the beginning of the alignment.
             The grid is filled up from left to right row by row, starting in the cells with left, top and diagonal cells filled (marked by $\rightarrowtriangle$).
             }
\end{table}

Then the alignment grid is filled up, starting with the cell that has left, top and diagonal cells filled (marked by $\rightarrowtriangle$ in table \ref{NW_fill_table1}) and continuing to the rightmost cell.
Cells are filled up by the following equation:
$$
C_{i,j} = max\left\{ (C_{i-1,j} + gp_{\text{down}}); (C_{i,j-1} + gp_{\text{right}}); (C_{i-1,j-1} + S_{i-1,j-1})  \right\}
$$
Cells are iterated through in the order $i=1,2,3,4$ and $j=1,2,3,4,5$, where $C_{i,j}$ is the $i$th row and $j$th column cell in the grid, $S_{i-1,j-1}$ is the score of aligning the $i$th, $j$th elements found by look-up in the score matrix (table \ref{distance_matrix}) and $gp_{\text{down}}$ and $gp_{\text{right}}$ is the gap penalty of the moving down and right respectively.
In this example the longest list is the true ancestral lineage, and therefore it has gaps disallowed enforced by setting these to negative infinity.
Gaps in the inferred sequence is allowed but not penalized: $gp_{\text{down}} = -\Inf$ and $gp_{\text{right}} = 0$.

The grid is filled and results store in table \ref{NW_full_table}.
The final alignment score is the number in the rightmost bottom cell.
\begin{table}[ht!]
\centering
\begin{tabular}{c|r|r|r|r|r|}
\rowcolor[HTML]{EFEFEF}
                                 & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}-} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}N} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}$A_{1t}$} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}$A_{2t}$} & \multicolumn{1}{c|}{\cellcolor[HTML]{EFEFEF}L} \\ \hline
\cellcolor[HTML]{EFEFEF}-        & 0                                              & -Inf                                            & -Inf                                                   & -Inf                                                   & -Inf                                            \\ \hline
\cellcolor[HTML]{EFEFEF}N        & -Inf                                            & 0                                              & 0                                                   & 0                                                   & 0                                            \\ \hline
\cellcolor[HTML]{EFEFEF}$A_{1i}$ & -Inf                                            & -Inf                                            & -1                                                     & -1                                                   & -1                                            \\ \hline
\cellcolor[HTML]{EFEFEF}L        & -Inf                                            & -Inf                                            & -Inf                                                   & -2                                                    & -1                                            \\ \hline
\end{tabular}
    \caption{
         \label{NW_full_table}
             The filled alignment grid, ready for tracing back the best alignment.
             The rightmost bottom cell contains the score for the best alignment.
             }
\end{table}

The last step is to traceback the best path through the alignment grid and store this alignment.
The traceback starts from the leaf sequence, in the right bottom corner, and ends with the naive sequence in the left top corner.
A diagonal step is equivalent to a sequence match, a left move is introducing a gap character in the inferred list and a move up is introducing a gap in the true list.
The path is found by moving backwards following the same path that was used to fill up the grid, and therefore using the same equation as to fill it, just reversed moving from bottom right cell to top left, $i=4,3,2,1$ and $j=5,4,3,2,1$:
$$
\text{move}_{i,j} = \text{which}\left\{ C_{i,j} = [(C_{i-1,j} + gp_{\text{down}}), (C_{i,j-1} + gp_{\text{right}}), (C_{i-1,j-1 } + S_{i-1,j-1})] \right\}
$$
Notice that this path has already been generated when the alignment grid was filled up and could be cached.
The resulting alignment and the penalty for each position is tabulated in table \ref{NW_final_alignment}.

\clearpage
Lastly the alignment score is normalized by the smallest possible alignment score i.e.\ no similarity between sequences in the lists.
This normalized number is the COAR value and it runs between 0 to 1.
In the presented example we only calculated the COAR value for the reconstructed ancestral lineage from one leaf, but by doing the calculations on all leaves on the tree and taking the average, would give the mean COAR value for the whole tree.
% Doing the same calculations on all leaves on the tree and summing this will give the total alignment score of the inferred phylogeny.
\begin{table}[ht!]
\centering
\begin{tabular}{|lcccc|}
\hline
\multicolumn{1}{|l|}{True}     & \multicolumn{1}{c|}{N} & \multicolumn{1}{c|}{$A_{1t}$} & \multicolumn{1}{c|}{$A_{2t}$} & T                      \\
\multicolumn{1}{|l|}{Inferred} & \multicolumn{1}{c|}{N} & \multicolumn{1}{c|}{$A_{1i}$} & \multicolumn{1}{c|}{-}        & T                      \\ \hline
Penalty                        & 0                      & -1                             & 0                           & 0                      \\ \hline
Max penalty                    & \multicolumn{1}{l}{0}  & \multicolumn{1}{l}{-3}        & \multicolumn{1}{l}{0}       & \multicolumn{1}{l|}{0} \\ \hline
COAR                           & \multicolumn{4}{c|}{-1/-3=0.333}                                                                                    \\ \hline
\end{tabular}
    \caption{
         \label{NW_final_alignment}
             The resulting alignment and the penalty for each positions.
             }
\end{table}





\subsection{Other validation metrics}

\subsubsection{Most recent common ancestor distance}
As an alternative to COAR we are also using a measure named the "most recent common ancestor" (MRCA) metric.
In this more simple measure of correctness of ASR the MRCA ancestral sequence of two leaves are found and compared in the true vs.\ inferred phylogeny.
By iterating through all pairwise combinations of leaves the MRCA distance can be found as the total sum:
$$
\MRCA_{\dist} = \sum_{i=1}^{N} \sum_{j=i+1}^{N} \dist(T_{\MRCA}(l_i, l_j), I_{\MRCA}(l_i, l_j))
$$
Where all the pairwise combinations of leaves $l_i$ and $l_j$ ($i \neq j$) are used to find their true ($T_{\MRCA}$) and inferred ($I_{\MRCA}$) MRCA.
The distance between the two ancestral sequences are found with the function $\dist(\cdot, \cdot)$ and summed over the whole tree.
In this work we use the Hamming distance as distance function.

Similar to COAR, ancestral sequences close to the root will have more influence on the result than sequences close to the tips.
The major difference is that MRCA is not scaled and not representing the result of a lineage reconstruction, and therefore the value has no meaningful interpretation aside from measuring performance of different methods on identical data.


\subsubsection{Robinson–Foulds distance}
The tree topology is the model that explains the order of branching events and relatedness of leaves, and therefore inferred ancestral sequences will always be tied to the topology.
Hence validating the ASR should also express some degree of correctness of the tree.
Regardless, it is interesting to have a method solely expressing the correctness of inferred tree topology and for this purpose we use the Robinson–Foulds (RF) distance \cite{robinson1981comparison}.
Briefly, RF distance is defined as the number of different tree partitions between two trees.
Tree partitions are made by cutting a branch connecting two nodes, all possible cuts are performed and the resulting split of taxa are sorted and recorded into two columns.
The after sorting the list of partitions they are compared true vs.\ inferred tree and for each partition mismatch the RF distance is increased by 1.



\subsection{Algorithms tested}
With the exception of a few methods there has been little published on BCR specific phylogeny software.
Barak et al.\ made some vaguely defined rules written into an algorithm they named IgTree \cite{Barak2008-fw}.
The description of IgTree is similar to that of MP and it is unclear whether there is any difference at all.
For that reason we use the MP algorithm \texttt{dnapars} from PHYLIP \cite{plotree1989phylip} as a substitute for IgTree and other related methods e.g.\ the one used in Tas et al.\ \cite{tas2016visualizing}.

In the paper from Doria-Rose et al.\ \cite{Doria-Rose2014-vi} they use the general time reversible (GTR) model implemented in MEGA5 \cite{tamura2011mega5}.
Also Kepler \cite{Kepler2013-sy} was using \texttt{dnaml} from the PHYLIP package to infer BCR phylogenetic trees.
To test these commonly used "out of the box" ML methods we use \texttt{dnaml}.

Two different models have been defined specifically for BCR evolution on protein level, the ``AB'' amino acid substitution matrix from Mirsky et al.\ \cite{mirsky2014antibody} and the HLP17 codon model from Hoehn et al.\ \cite{Hoehn2016-wg}, both implemented using codonPhyML \cite{gil2013codonphyml}.
The AB substitution matrix is just a standard amino acids substitution rate matrix but fitted to substitutions observed in BCR sequences and yielding a symmetric rate matrix that assumes equilibrium.
Recently Sheng et al.\ found large discrepancies between their findings and the AB substitution matrix \cite{sheng2017gene}, leading us to exclude the AB model from our evaluation.
Instead we test the HLP17 model implemented in the software IgPhyML (\url{github.com/kbhoehn/IgPhyML}).
The HLP17 model is based on a GY94 model \cite{goldman1994codon} with additional parameters accounting for AID hot/cold spots and thereby attempting to address the context sensitivity of SHM.

Lastly we also test the performance of an unpublished method that uses a likelihood based ranking of equally parsimonious trees, we call this method GCtree, for genotype collapsed tree.
Briefly, the GCtree likelihood function is based on the assumption that the germinal center reaction can be modelled as a binary Galton-Watson process \cite{harris2002theory}.
Some genotypes have many observations while others have fewer, the Galton-Watson process will favour a high abundance genotype to be the parent for a low abundance genotype.
Each MP tree is evaluated and ranked according to its fit and then the highest likelihood tree is picked out as the GCtree inferred tree.
The GCtree method assumes getting correct genotype abundances and will be sensitive to experimental errors in these.



\subsection{Simulated data}
Simulations were performed using both the neutral branching process and the affinity simulation described in chapter 3.
Both simulation, inference and evaluation was wrapped into an SCons script \cite{fomel2007reproducible} using nestly \cite{mccoy2012nestly} to loop through all combinations of requested parameters.
This script is available in the codebase of \texttt{GCtree} (static copy used in this work: \url{github.com/krdav/master_thesis_code}).
SCons commands can be found in appendix C.





\section{Results - comparing algorithms for B cell phylogenetic reconstruction}
The most suitable dataset for clonal family phylogeny is data collected from a single GC similar to that in Tas et al.\ \cite{tas2016visualizing}, but these unlike single cell sequences most data is generated from bulk RNA extracts from peripheral blood mononuclear cell (PBMC).
To adjust the simulation parameters to recapitulate a given dataset we both used the single cell Tas et al.\ dataset and an HTS dataset generated from PBMCs from HIV infected individuals (figures in appendix B).
The HTS dataset was clustered using \texttt{partis} resulting in hundreds of clonal families.
A seed sequence, known from previous lab tests to be an HIV neutralizing antibody, was used to isolate HIV relevant clonal families.
The size of the clonal families varied substantially (figure \ref{fig:Laura-neutsim_Laura-data}) but serve as a more realistic dataset case than the single cell data.

Simulation parameters were adjusted in order to recapitulate two measures: a) distribution of sequence across the length of the tree and b) divergence among sequences.
Measure a) is captured by plotting the cumulative distribution function (CDF) of the distance to the naive/root sequence ((a) in figure \ref{fig:Laura-neutsim_Laura-data} and \ref{fig:Laura-affsim_Laura-data}).
Measure b) is captured by plotting the CDF of the nearest neighbor distance ((b) in figure \ref{fig:Laura-neutsim_Laura-data} and \ref{fig:Laura-affsim_Laura-data}).
The neutral simulation with a large $\lambda$ will naturally vary a lot in population size and therefore had no problem fitting into the large span of possible summary statistics, defined by two chosen clonal family representatives from the HTS dataset (figure \ref{fig:Laura-neutsim_Laura-data}).
The nature of the affinity simulation forces it to maintain a rather constant population size defined by its carrying capacity, so instead of taking the full cell population, the GC was down-sampled to 150 sequence and the variance in the number of observed sequences comes from the fact that some sequences are identical at DNA level and deduplicated (figure \ref{fig:Laura-affsim_Laura-data}).

\begin{figure}[!ht]
    \begin{center}
    \includegraphics[width=0.8\textwidth]{figures/Laura-neutsim_Laura-data.pdf}\newline%
    \end{center}
    \vspace{-14mm} \hspace{44mm} (a) \hspace{50mm} (b)
    \caption{
        \label{fig:Laura-neutsim_Laura-data}
        Summary statistics for the unique sequences simulated under a neutral model fitted to HTS data.
        The two thick dark grey lines represents the characteristics of two clonal families extracted by \texttt{partis} seed clustering on HTS data.
        Smaller light grey lines are showing the 100 simulated datasets.
        Non-default parameters used: $T=5$, $\lambda=2.5$, $\lambda_{\mut}=3$
    }
\end{figure}
\clearpage
\begin{figure}[!ht]
    \begin{center}
    \includegraphics[width=0.8\textwidth]{figures/Laura-affsim_Laura-data.pdf}\newline%
    \end{center}
    \vspace{-14mm} \hspace{44mm} (a) \hspace{50mm} (b)
    \caption{
        \label{fig:Laura-affsim_Laura-data}
        Summary statistics for the unique sequences simulated under the affinity model fitted to HTS data.
        The two thick dark grey lines represents the characteristics of two clonal families extracted by \texttt{partis} seed clustering on HTS data.
        Smaller light grey lines are showing the 100 simulated datasets.
        Non-default parameters used: $T=90$, $n=150$, $\lambda_{\mut}=0.25$
    }
\end{figure}


Looking at RF distance for the neutral simulation there is only small differences and only the distribution of RF distances for MP is shift up compared to the others (significant $p<0.05$ in Mann–Whitney U (MWU) test), see figure \ref{fig:Laura-neutsim_valid}.
Likewise the quartiles are slightly shifted upward for MP in the comparison of MRCA distances.
We consider COAR the most important metric because it has a direct interpretation related to the purpose of the tree, and for COAR there appears to be no significant difference between the methods when simulating under neutral conditions.
The average COAR values are ranging from 1.76E-04 to 2.37E-04 (appendix A table \ref{tab:Laura-neutsim_vali}) corresponding to approx. 10\% chance of one nucleotide error per reconstructed sequence in an ancestral lineage.
Similar, but somewhat large differences, are observed for neutral simulation using parameters fitted to the Tas et al.\ dataset (figure \ref{fig:Tas-neutsim_vali} in appendix B).
Should we rank the methods based on all metrics from best to worst the rank would be: GCtree, dnaml, IgPhyML, Parsimony.
But the first three methods are virtually the same.
% The Tas et al.\ dataset fitted simulations also experience a similar range of expected errors in ASR, though slightly lower because of the fewer sequences simulated (table \ref{tab:Tas-neutsim_vali} in appendix A).

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/Laura-neutsim_valid.pdf}
    \caption{
        \label{fig:Laura-neutsim_valid}
        Simulation with 100 repeats of a neutral branching process.
        Each simulation is plotted in a single column ranked according to the number of equally parsimonious trees for the simulation.
        The ensemble of equally parsimonious trees are shown as a box plot while the other methods are plotted as jittered dots.
        On the right the aggregated result is shown.
    }
\end{figure}
\clearpage


For the affinity simulations we allow genotypes to reappear in another clade during simulations i.e.\ homoplasy is allowed and this prevents us from calculating the RF distance.
However, for both MRCA and COAR there is no significant differences resulting in a tie between all the inference methods (figure \ref{fig:Laura-affsim_valid}).
Similar characteristics are observed for affinity simulations fitted to the Tas et al.\ dataset, although with slightly worse performance of MP and IgPhyML (figure \ref{fig:Tas-affsim_vali} in appendix B).
Again, the best to worse rank would be: GCtree, dnaml, IgPhyML, Parsimony, but with a small effect size separating them.

\begin{figure}[!ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/Laura-affsim_valid.pdf}
    \caption{
        \label{fig:Laura-affsim_valid}
        Simulation with 100 repeats of the affinity simulation.
        Each simulation is plotted in a single column ranked according to the number of equally parsimonious trees for the simulation.
        The ensemble of equally parsimonious trees are shown as a box plot while the other methods are plotted as jittered dots.
        On the right the aggregated result is shown.
    }
\end{figure}





\clearpage
\section{Discussion and conclusion}
We have presented the COAR metric as an objective function tailored for evaluating ASR on a non-fixed inferred phylogeny.
COAR is different from other tree metrics by being robust towards tree topology errors irrelevant for ASR and by being directly interpretable as the expected per-site error of the sequences in a reconstructed lineage.
Using COAR and other tree metrics we went on to show that reconstruction of sequences along an ancestral lineage is robust and only rarely accumulate errors regardless of the inference method tested.
In a worst-case scenario we found an expected one nucleotide error per reconstructed lineage sequence, based on affinity simulation with 4-8 sequences (including the a priori known root and leaf) in a lineage, see b) in figure \ref{fig:Laura-affsim_runstat} appendix B.

We use two kind of simulations, with and without selection.
A neutral branching process serve as a good baseline but is not realistic compared to the fast and stringent selection process which is undertaken in the GC reaction.
The simulation with added affinity selection attempts to address this issue by including a semi-mechanistic model for BCR-antigen affinity, challenging the inference methods with both epistasis and homoplasy.
It is therefore not surprising to see that inference made on affinity simulations obtain higher COAR values than those on neutral simulations under comparable conditions.
What we do find surprising is, that the accuracy of all inference methods appear to be equally affected by the imposed affinity selection.
We would have expected a codon based model like IgPhyML to have an advantage compared to the nucleotide based models, because affinity selection is strictly acting on protein level, and hence there is a preference for synonymous over non-synonymous mutations that is an integrated part of a codon model but not accounted for in a nucleotide model.
IgPhyML should also have an advantage over the other methods due to its model incorporating AID hot/cold spot motifs.
IgPhyML is marginalizing over motifs that span multiple codons to achieve site independence, and although this might water out some signal, it should still retain some of the signal from mutational context bias.
However, again this does not seem to improve the inference by IgPhyML over the other methods.

Looking at typical trees simulated from both the neutral and affinity selected process (see trees in appendix B) we see that trees are relatively shallow i.e.\ the number of internal nodes from the leaf to the root is small.
This of course makes it easier to get a low COAR score because there are only few states to reconstruct.
In the affinity model trees are simulated over many generations but still appear shallow because cells with low affinity are lost during the competitive selection of maturation.
Such "memory loss" of lower affinity variants will result in a tree with a long trunk, extending from the root to a most recent common ancestor of a bushy canopy of leaves, similar to observations made by Yaari et al.\ \cite{yaari2015mutation} (visualized in b) in figure \ref{fig:Laura-affsim_runstat} in appendix B).
This trait could explain why there is no apparent benefit of integrating AID motifs into an inference algorithm like IgPhyML, the effect could in fact be positive but too small to be detected in our ASR validation due to shallow trees.
Hoehn et al.\ describing IgPhyML provides results of their own simulation study based on a fixed tree topology inferred from clonal BCR data ranging from approx.\ 300 to 1000 taxa.
With these trees containing more taxa than our simulations, they show that integration of AID hotspots does increase ASR correctness slightly compared to the GY94 codon model.
Still, they only get an average of 3\% improvement in terms of fewer errors (at h=2) over the regular GY94 model, confirming our findings of high similarity between methods.

The overall performance of all the evaluated inference methods is very similar.
There is a consistent ranking that puts GCtree first, dnaml and IgPhyML second and Parsimony last, but it must be stressed that the difference in effect size is very small and that the performance can be regarded as practically equivalent.
GCtree does stand out as the most consistently better performing algorithm but it is also dependent on genotype abundance data, which is not readily available for most BCR data sets.
Abundance data could potentially be extracted from standard HTS data, but because of sequencing errors and primer biases these abundances are not expected to be reliable.
With the recent introduction of UMIs, we expected most future datasets will have much more reliable abundance information, being an opportunity to integrate abundance data in methods such as GCtree to direct phylogenetic inference.




\section{Conclusion}
The problem of inferring BCR phylogenies appear to be insensitive to the method used on the simulation regimes tested.
With the GCtree inference being significantly better than the other tested method, we suggest that this is the first choice if reliable abundance information exists.
Otherwise, if GCtree cannot be used because of missing abundance information, the methods tested are practically equivalent suggesting that users should care mostly about which tool provide the most convenient solution to inferring their BCR phylogeny.
It remains to be tested whether different sampling conditions, such as time series sampling, will alter the results.
Likewise, it is yet to be determined whether joint reconstruction will do any improvement over marginal reconstruction.


